{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a03329",
   "metadata": {},
   "source": [
    "## Training a new Tokenizer from an old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09f6523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3380684917124884ac2b48adb8036c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391068f966124d67ac71dfbf27d3e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0f7f8582cc4816909c84cc13ea1886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dab7c28f744ca3abcacd3e4a8ea421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cbc95514314ca3b3958d208af7c6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8ffd62faf74aa6a199c696bdeeac53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0d4cccfa784a4e9613872f05c86c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b22afba87d450f8c861ac747e22154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/412178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0b125785234ee0a249e607809e4cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/22176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98b0a498cfa484597689510cc2b65ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/23107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset ('code_search_net','python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f2e17c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repository_name': 'ageitgey/face_recognition',\n",
       " 'func_path_in_repository': 'examples/face_recognition_knn.py',\n",
       " 'func_name': 'train',\n",
       " 'whole_func_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'language': 'python',\n",
       " 'func_code_string': 'def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \"\"\"\\n    Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.\\n    \"\"\"\\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf',\n",
       " 'func_code_tokens': ['def',\n",
       "  'train',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'model_save_path',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'knn_algo',\n",
       "  '=',\n",
       "  \"'ball_tree'\",\n",
       "  ',',\n",
       "  'verbose',\n",
       "  '=',\n",
       "  'False',\n",
       "  ')',\n",
       "  ':',\n",
       "  'X',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  'y',\n",
       "  '=',\n",
       "  '[',\n",
       "  ']',\n",
       "  '# Loop through each person in the training set',\n",
       "  'for',\n",
       "  'class_dir',\n",
       "  'in',\n",
       "  'os',\n",
       "  '.',\n",
       "  'listdir',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ')',\n",
       "  ':',\n",
       "  'if',\n",
       "  'not',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'isdir',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'continue',\n",
       "  '# Loop through each training image for the current person',\n",
       "  'for',\n",
       "  'img_path',\n",
       "  'in',\n",
       "  'image_files_in_folder',\n",
       "  '(',\n",
       "  'os',\n",
       "  '.',\n",
       "  'path',\n",
       "  '.',\n",
       "  'join',\n",
       "  '(',\n",
       "  'train_dir',\n",
       "  ',',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  ')',\n",
       "  ':',\n",
       "  'image',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'load_image_file',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ')',\n",
       "  'face_bounding_boxes',\n",
       "  '=',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_locations',\n",
       "  '(',\n",
       "  'image',\n",
       "  ')',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '!=',\n",
       "  '1',\n",
       "  ':',\n",
       "  '# If there are no people (or too many people) in a training image, skip the image.',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Image {} not suitable for training: {}\"',\n",
       "  '.',\n",
       "  'format',\n",
       "  '(',\n",
       "  'img_path',\n",
       "  ',',\n",
       "  '\"Didn\\'t find a face\"',\n",
       "  'if',\n",
       "  'len',\n",
       "  '(',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '<',\n",
       "  '1',\n",
       "  'else',\n",
       "  '\"Found more than one face\"',\n",
       "  ')',\n",
       "  ')',\n",
       "  'else',\n",
       "  ':',\n",
       "  '# Add face encoding for current image to the training set',\n",
       "  'X',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'face_recognition',\n",
       "  '.',\n",
       "  'face_encodings',\n",
       "  '(',\n",
       "  'image',\n",
       "  ',',\n",
       "  'known_face_locations',\n",
       "  '=',\n",
       "  'face_bounding_boxes',\n",
       "  ')',\n",
       "  '[',\n",
       "  '0',\n",
       "  ']',\n",
       "  ')',\n",
       "  'y',\n",
       "  '.',\n",
       "  'append',\n",
       "  '(',\n",
       "  'class_dir',\n",
       "  ')',\n",
       "  '# Determine how many neighbors to use for weighting in the KNN classifier',\n",
       "  'if',\n",
       "  'n_neighbors',\n",
       "  'is',\n",
       "  'None',\n",
       "  ':',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'int',\n",
       "  '(',\n",
       "  'round',\n",
       "  '(',\n",
       "  'math',\n",
       "  '.',\n",
       "  'sqrt',\n",
       "  '(',\n",
       "  'len',\n",
       "  '(',\n",
       "  'X',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  ')',\n",
       "  'if',\n",
       "  'verbose',\n",
       "  ':',\n",
       "  'print',\n",
       "  '(',\n",
       "  '\"Chose n_neighbors automatically:\"',\n",
       "  ',',\n",
       "  'n_neighbors',\n",
       "  ')',\n",
       "  '# Create and train the KNN classifier',\n",
       "  'knn_clf',\n",
       "  '=',\n",
       "  'neighbors',\n",
       "  '.',\n",
       "  'KNeighborsClassifier',\n",
       "  '(',\n",
       "  'n_neighbors',\n",
       "  '=',\n",
       "  'n_neighbors',\n",
       "  ',',\n",
       "  'algorithm',\n",
       "  '=',\n",
       "  'knn_algo',\n",
       "  ',',\n",
       "  'weights',\n",
       "  '=',\n",
       "  \"'distance'\",\n",
       "  ')',\n",
       "  'knn_clf',\n",
       "  '.',\n",
       "  'fit',\n",
       "  '(',\n",
       "  'X',\n",
       "  ',',\n",
       "  'y',\n",
       "  ')',\n",
       "  '# Save the trained KNN classifier',\n",
       "  'if',\n",
       "  'model_save_path',\n",
       "  'is',\n",
       "  'not',\n",
       "  'None',\n",
       "  ':',\n",
       "  'with',\n",
       "  'open',\n",
       "  '(',\n",
       "  'model_save_path',\n",
       "  ',',\n",
       "  \"'wb'\",\n",
       "  ')',\n",
       "  'as',\n",
       "  'f',\n",
       "  ':',\n",
       "  'pickle',\n",
       "  '.',\n",
       "  'dump',\n",
       "  '(',\n",
       "  'knn_clf',\n",
       "  ',',\n",
       "  'f',\n",
       "  ')',\n",
       "  'return',\n",
       "  'knn_clf'],\n",
       " 'func_documentation_string': 'Trains a k-nearest neighbors classifier for face recognition.\\n\\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\\n\\n     (View in source code to see train_dir example tree structure)\\n\\n     Structure:\\n        <train_dir>/\\n        ├── <person1>/\\n        │   ├── <somename1>.jpeg\\n        │   ├── <somename2>.jpeg\\n        │   ├── ...\\n        ├── <person2>/\\n        │   ├── <somename1>.jpeg\\n        │   └── <somename2>.jpeg\\n        └── ...\\n\\n    :param model_save_path: (optional) path to save model on disk\\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\\n    :param verbose: verbosity of training\\n    :return: returns knn classifier that was trained on the given data.',\n",
       " 'func_documentation_tokens': ['Trains',\n",
       "  'a',\n",
       "  'k',\n",
       "  '-',\n",
       "  'nearest',\n",
       "  'neighbors',\n",
       "  'classifier',\n",
       "  'for',\n",
       "  'face',\n",
       "  'recognition',\n",
       "  '.'],\n",
       " 'split_name': 'train',\n",
       " 'func_code_url': 'https://github.com/ageitgey/face_recognition/blob/c96b010c02f15e8eeb0f71308c641179ac1f19bb/examples/face_recognition_knn.py#L46-L108'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = dataset.copy()\n",
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cddda8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "training_corpus = (\n",
    "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    ")\n",
    "print (len (next(iter(training_corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b36fd987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "raw_datasets_1 = load_dataset ('code_search_net','python' , split='train' ,streaming=True)\n",
    "print (len (next(iter(raw_datasets_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74554b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object square_generator at 0x000001A02C8D50B0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_generator(n):\n",
    "    for i in range(n):\n",
    "        yield i ** 2\n",
    "\n",
    "# Using the generator\n",
    "gen = square_generator(5)\n",
    "for square in gen:\n",
    "    print(square)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd795aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "475d9bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "old_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab87d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ġadd',\n",
       " '_',\n",
       " 'n',\n",
       " 'umbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ġb',\n",
       " '):',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ\"\"\"',\n",
       " 'Add',\n",
       " 'Ġthe',\n",
       " 'Ġtwo',\n",
       " 'Ġnumbers',\n",
       " 'Ġ`',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ġand',\n",
       " 'Ġ`',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " 'Ċ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġ',\n",
       " 'Ġreturn',\n",
       " 'Ġa',\n",
       " 'Ġ+',\n",
       " 'Ġb']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db4c54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4dd9d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=52000, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb010a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=52000, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_2 = old_tokenizer.train_new_from_iterator(raw_datasets[\"train\"][\"whole_func_string\"], 52000)\n",
    "tokenizer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275953e0",
   "metadata": {},
   "source": [
    "Lets check that what our new tokeizer have learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6550ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "610ccda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "old token len = 36\n",
      "new token len = 27\n",
      "new token2 len = 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"\"\"\n",
    "old token len = {len (old_tokenizer.tokenize(example))}\n",
    "new token len = {len (tokenizer.tokenize(example))}\n",
    "new token2 len = {len (tokenizer_2.tokenize(example))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747954a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97799492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
